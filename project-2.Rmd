---
title: "STA 521 Project 2"
author: "Eli Gnesin (ejg45) & Caleb Woo (csw57)"
date: "2022-12-06"
number-sections: true
bibliography: references.bib
output: pdf_document
---

# Data Collection and Exploration

```{r setup-packages, echo=FALSE, message=FALSE}
library(tidyverse)
library(GGally)
library(ggplot2)
library(lubridate)
library(magrittr)
library(gridExtra)
library(latex2exp)
library(stats)
library(plotly)
library(rjson)
library(kableExtra)
library(knitr)
library(kableExtra)
library(caret)
library(tree)
library(rpart)

source("CVmaster.R")
source("image_split.R")

knitr::opts_chunk$set(fig.align="center", echo=FALSE, eval=TRUE,
                      message=FALSE, warning=FALSE, error=FALSE)
```

```{r read-data}
columns = c("image", "Y", "X", "Label", "NDAI", "SD", "CORR", 
            "DF", "CF", "BF", "AF", "AN")

image1 = read.table("image_data/imagem1.txt", header=FALSE)
image1 = cbind(rep(1, nrow(image1)), image1)
colnames(image1) = columns

image2 = read.table("image_data/imagem2.txt", header=FALSE)
image2 = cbind(rep(2, nrow(image2)), image2)
colnames(image2) = columns

image3 = read.table("image_data/imagem3.txt", header=FALSE)
image3 = cbind(rep(3, nrow(image3)), image3)
colnames(image3) = columns

data = rbind(image1, image2, image3)
```

## Summary of the Paper

In 2008, Yu et al. published "Daytime Arctic Cloud Detection Based on Multi-Angle Satellite Data With Case Studies" [@shi_yu_clothiaux_braverman_2008]. The purpose of the study was to explore the state of daytime Arctic cloud classification, and propose a new "Enhanced Linear Correlation Matching Algorithm" and classification system that is less reliant on manual human classification.

The data used in the study was collected by the Multiangle Imaging SpectroRadiometer (MISR) on NASA's Terra satellite, and for this study, 10 orbits of the satellite path over the Arctic, northern Greenland, and Baffin Bay, collected between April and September 2002, were used. Together, this dataset comprises 57 "data units" of three MISR blocks each (with a block being $\frac{1}{180}$ of a path), totaling 7.11 million pixels of 1.1 kilometer resolution (as well as 275 meter resolution for red radiation measurements). The labels of cloud cover and no-cloud cover (as well as an "ambiguous" label), were provided by industry experts.

The research team then used the data to construct three "physical features," CORR, SD, NDAI. CORR is the average of the linear correlations of two pairs of radiation measurements (Af/An and Bf/An), where higher values suggest a cloud-free image. The second, SD, is the standard deviation of the An radiation measurements, used to help detect "smooth cloud-free surfaces", and NDAI is the average of two radiation measurements over a 1.1 kilometer spacial resolution. Using these features, the research team created two decision rules to label a 1.1 km square pixel as clear, and with setting appropriate thresholds, reached over 91% agreement with the expert labels and 100% coverage in labeling. From this, the team demonstrated that the three physical features were sufficient to accurately classify cloud cover in arctic environments with better spatial coverage and real-time adaptive thresholding to improve the robustness of the model. Furthermore, the ELCM algorithm was used to train QDA to provide probability labels for partly cloudy scenes and was found to be effective in identifying cloud boundaries. By improving understanding of the flow of radiation through the atmosphere and how clouds respond to changes in arctic climate, this study is the first step towards analyzing how changing cloud properties may improve or destroy the changes in the Arctic brought about by climate change.

## Summary of the Data

```{r summary-pixels}
class_count <- data %>%
  count(Label)
class_count$Label <- c("Not Cloud", "Unlabeled", "Cloud")
class_count$n <- 100*(class_count$n/nrow(data))
names(class_count)[2] <- "% of pixels"
class_count %>%
  kbl(digits = 3) %>%
  kable_styling(latex_options = "HOLD_position", full_width = F)
```

```{r maps}
map1 <- ggplot(data=image1, aes(x=X, y=Y, color=factor(Label))) +
  geom_point() +
  coord_quickmap(expand = F, clip = "on") +
  labs(title = "Image 1") +
  scale_color_manual(labels = c("Not Cloud", "Unlabeled", "Cloud"),
                     values = c("chocolate3", "darkseagreen", "deepskyblue"),
                     name = "Label") +
  theme(legend.position = "none")
map2 <- ggplot(data=image2, aes(x=X, y=Y, color=factor(Label))) +
  geom_point() +
  coord_quickmap(expand = F, clip = "on") +
  labs(title = "Image 2") +
  scale_color_manual(labels = c("Not Cloud", "Unlabeled", "Cloud"),
                     values = c("chocolate3", "darkseagreen", "deepskyblue"),
                     name = "Label") +
  theme(legend.position = "none")
map3 <- ggplot(data=image3, aes(x=X, y=Y, color=factor(Label))) +
  geom_point() +
  coord_quickmap(expand = F, clip = "on") +
  labs(title = "Image 3") +
  scale_color_manual(labels = c("Not Cloud", "Unlabeled", "Cloud"),
                     values = c("chocolate3", "darkseagreen", "deepskyblue"),
                     name = "Label")
grid.arrange(map1, map2, map3, nrow=1, widths=c(1, 1, 1.65))
```

Similar to the ELCM-QDA results from the paper, we observe many ambiguous and unlabeled points around the cloud boundaries which separate the cloud pixels from the non-cloud pixels. An i.i.d. assumption for the samples cannot be justified for this dataset because individual pixels seem to depend on the pixels around it. If the data appeared to be i.i.d. we would expect a random scatter of pixels at any given region of an image. However, we observe clear spatial trends where cloud pixels are near other cloud pixels, unlabeled pixels border the clouds, and non-cloud pixels are near other non-cloud pixels. Therefore, individual pixels are essentially meaningless outside of the context of nearby pixels so we cannot make an i.i.d. assumption on the data.

## Exploratory Data Analysis

We now continue with a short exploration of the data itself. First, we look at the pairwise correlations between the features, excluding the coordinates:

```{r correlations}

cor(data[,4:12], data[,4:12]) %>%
  kable(format = "simple", digits =3)
```

From these correlations, some trends stand out. All three of the "physical features" in the paper (NDAI, SD, CORR), are positively correlated with label, which indicates that *higher* values of all three of these features are associated with a label of +1, meaning cloud cover. In contrast, however, four of the five given radiance angles show negative correlation with the label variable, indicating that *lower* values of radiance are generally associated with cloud cover. We can also compare differences between the features in the two classes by considering the densities of the features separated by label:

```{r density-plots, fig.height=3, fig.width=8}
colors = c("clouds" = "deepskyblue", 
           "noclouds" = "chocolate3",
           "other" = "darkseagreen")

g1 = ggplot() +
  geom_density(aes(x = NDAI, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = NDAI, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = NDAI, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "NDAI",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g2 = ggplot() +
  geom_density(aes(x = log(SD), color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = log(SD), color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = log(SD), color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "log(SD)",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g3 = ggplot() +
  geom_density(aes(x = CORR, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = CORR, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = CORR, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "CORR",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g4 = ggplot() +
  geom_density(aes(x = DF, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = DF, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = DF, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "DF",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g5 = ggplot() +
  geom_density(aes(x = CF, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = CF, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = CF, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "CF",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g6 = ggplot() +
  geom_density(aes(x = BF, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = BF, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = BF, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "BF",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g7 = ggplot() +
  geom_density(aes(x = AF, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = AF, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = AF, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "AF",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

g8 = ggplot() +
  geom_density(aes(x = AN, color = "clouds", fill = "clouds"), 
               data = data %>% filter(Label == 1), 
               alpha = 0.6) +
    geom_density(aes(x = AN, color = "noclouds", fill = "noclouds"), 
               data = data %>% filter(Label == -1), 
               alpha = 0.6) +
    geom_density(aes(x = AN, color = "other", fill = "other"), 
               data = data %>% filter(Label == 0), 
               alpha = 0.6) +
  labs(title = "AN",
       x = element_blank(),
       y = element_blank()) +
  scale_fill_manual(values = colors) +
  scale_color_manual(values = colors) +
  theme_minimal() + 
  theme(legend.position = "none")

grid.arrange(g1,g2,g3,g4,g5,g6,g7,g8,nrow=2)
```
These density plots reinforce the same ideas seen in the correlations above. In the three "physical features", the "cloud" labeled points have densities higher than the "non-cloud" labeled points, and conversely, for four of the five radiances (all except for DF), the bulk of the density for the "non-cloud" labeled points is above that of the cloud labeled points. Interestingly, the radiance densities for the "cloud" labeled points are generally unimodal, whereas the radiances for the "non-cloud" labeled points are generally bimodal, with the larger mode above the cloud density mode and the smaller mode below. This helps explain the need for the physical features; the radiances are less uniformly separable, and thus have less predictive power than the physical features. 

# Preparation

## Data Split

In splitting the dataset into training, validation, and test subsets, it is important to preserve the structure of the data, that is, that the observations are denoted by their X and Y spatial coordinates, and any split of the data would have to preserve this spatial structure. One method for doing so is to carve each image up into some $k$ blocks, and then to randomly permute the block identifiers, the range of numbers from 1 to $3k$, and then take a split from the random block permutations. Such a method does preserve the spatial structure of the data, as each point is in a set with some (or all if not an edge) of the points around it. The random permutation of the blocks also ensures that, while the spatial structure of the points relative to each other is preserved, the structure of the image is not considered in the model, such that the orientation and structure of a individual image is a considered feature of the model.

A second method for splitting the data into three sets is to assign all data from images 1 and 3 to the training data. Then we can split the image 2 data in half to assign each half to the validation and test sets respectively. By doing so, we retain the majority of the data for training to better fit our classifiers. In addition, by splitting image 2 in half, we still retain the spatial structure of the data for the validation and test sets. We believe that image 2 is the best choice to split in half for our validation and test sets because each half contains numerous samples from each class. Looking at the maps of the validation and test sets below, we see that each set contains a sizable number of cloud, unlabeled, and non-cloud samples so that we are validating and testing our classifiers on a similar number of samples per class.

```{r val-test-maps}
split_ims <- image_split(data)

val_map <- ggplot(data=split_ims$val, aes(x=X, y=Y, color=factor(Label))) +
  geom_point() +
  coord_quickmap(expand = F, clip = "on") +
  labs(title = "Validation Set") +
  scale_color_manual(labels = c("Not Cloud", "Unlabeled", "Cloud"),
                     values = c("chocolate3", "darkseagreen", "deepskyblue"),
                     name = "Label") +
  theme(legend.position = "none")
test_map <- ggplot(data=split_ims$test, aes(x=X, y=Y, color=factor(Label))) +
  geom_point() +
  coord_quickmap(expand = F, clip = "on") +
  labs(title = "Test Set") +
  scale_color_manual(labels = c("Not Cloud", "Unlabeled", "Cloud"),
                     values = c("chocolate3", "darkseagreen", "deepskyblue"),
                     name = "Label")
grid.arrange(val_map, test_map, nrow=1)
```

## Baseline

We can now split the data using the methods outlined above and run a "classifier" which just sets all points to label $-1$, indicating cloudlessness. For the block splitting method, we split each image into 64 blocks, for a total of 192 blocks, of which 30 are for testing, 30 are for validation, and 132 are for training. This method gives a validation set misclassification rate of $63.0\%$ and a test set misclassification rate of $65.3\%$, which is about in line with the overall rate of $-1$ labels being $35-36\%$. This classifier would yield high accuracy if the image data was unbalanced to be mostly cloudless images, but in a scenario where the majority of points are not labeled $-1$, it is not a particularly accurate classifier.

```{r}
set.seed(521)

tl = data %>%
  pull(Label)
td = data %>%
  select(-Label)


td$block = rep(0, nrow(td))
labels_block = numeric()
ims = distinct(td %>% select(image)) %>% pull(image)
snum = 0
  
for (im in ims){
  xvals = td %>%
    filter(image == im) %>%
    pull(X) %>%
    unique()
  yvals = td %>%
    filter(image == im) %>%
    pull(Y) %>%
    unique()
  
  xsplit = split(xvals,
                 cut(seq_along(xvals),
                     8,
                     labels = FALSE))
  
  ysplit = split(yvals,
                 cut(seq_along(yvals),
                     8,
                     labels = FALSE))

  for (xs in xsplit){
    for (ys in ysplit){
      snum = snum + 1
      td = td %>%
        mutate(block = ifelse(
          ((image == im) & (X %in% xs) & (Y %in% ys)), 
          snum, block))
      labels_block = c(labels_block, 
                            rep(snum, 
                                nrow(td %>%
                                       filter((image == im) & 
                                                (X %in% xs) & 
                                                (Y %in% ys)))))
    }
  }
}

#Splitting the blocks
bks = sample(seq.int(from = 1, to = snum, by = 1))

train = tl[labels_block %in% bks[1:132]]
valid = tl[labels_block %in% bks[133:162]]
testy = tl[labels_block %in% bks[163:192]]

invisible(mean(valid != -1))
invisible(mean(testy != -1))

```

Next, we will run this trivial classifier on our image splitting method where we split image 2 in half for the validation and test sets. This method gives a validation set misclassification rate of $59.7\%$ and a test set misclassification rate of $52.7\%$, which is about in line with the overall rate of $-1$ labels being $40.3\%$ and $47.3\%$ respectively. Once again, this trivial classifier will have a high average accuracy if the majority of the points are $-1$ (cloudless). But since the majority of the points are not cloudless, this trivial classsifier will be very inaccurate.

```{r baseline-image-split}
val_labels <- split_ims$val$Label
val_trivial <- rep(-1, length(val_labels))
#print(sum(val_labels == -1)/length(val_labels))
#print(sum(val_trivial != val_labels)/length(val_trivial))

test_labels <- split_ims$test$Label
test_trivial <- rep(-1, length(test_labels))
#print(sum(test_labels == -1)/length(test_labels))
#print(sum(test_trivial != test_labels)/length(test_trivial))
```

## First Order Importance

```{r corrplot}
corrplot::corrplot(cor(data[,4:12]), type="upper", tl.col="black")
```

In general, the best set of features should include features that are strongly correlated with the response, in this case label, and features that are weakly correlated with each other. Looking at the correlation plot above, NDAI and CORR are fairly strongly correlated with label and are fairly weakly correlated with each other. Although SD is weakly correlated with CORR which would make it a good feature to include with CORR, it may not be preferable because it is strongly correlated with NDAI and weakly correlated with label. Looking at the scatter plots of the 3 combinations of these 3 variables below, we see that the -1 and 1 labels corresponding to the non-cloud and cloud labels are more easily separated with NDAI and CORR or with log(SD) and CORR. Therefore, we believe that NDAI and CORR are the best 2 features to select out of the 3 constructed physical features because they are both strongly correlated with the response label, are fairly weakly correlated with each other, and lead to more separable groups of labels.

```{r scatter-compare}
scatter1 <- ggplot(data, aes(x=NDAI, y=log(SD), color=factor(Label))) +
  geom_point(alpha=0.5) +
  theme(legend.position = "none")
scatter2 <- ggplot(data, aes(x=NDAI, y=CORR, color=factor(Label))) +
  geom_point(alpha=0.5) +
  theme(legend.position = "none")
scatter3 <- ggplot(data, aes(x=log(SD), y=CORR, color=factor(Label))) +
  geom_point(alpha=0.5)

grid.arrange(scatter1, scatter2, scatter3,
             nrow=1, ncol=3, widths=c(1, 1, 1.5))
```

Now looking at the radiance angles, the most promising features include BF, AF, and AN because they are all fairly highly correlated with label. Although the correlation of BF with label is slightly weaker, it has a weaker correlation with CORR which may make it a better feature to combine with NDAI and CORR.

Below is a table of the mutual information between each feature and the response label. The entropy of the empirical probability distributions are computed to quantify the amount of information obtained about label when observing one of the features. NDAI is certainly a good feature to select because it has the highest mutual information with label by a large margin. Although SD has a higher mutual information than CORR, since it is highly correlated with NDAI and CORR still has a high mutual information, we prefer to choose CORR alongside NDAI. As expected, the BF, AF, and AN radiance angles have a higher mutual information with label than the DF and CF radiance angles. Since the AF and AN radiance angles only have a slightly higher mutual information than the BF radiance angle, we may prefer to choose the BF radiance angle because it has a weaker correlation with CORR compared to the AF and AN radiance angles. The next table shows the table of the mutual information between the combination of NDAI and CORR with BF, AF, and AN respectively to see which combination of the 3 variables results in the greatest mutual information. The combinations with BF and AN both result in the highest mutual information. This further justifies combining the BF radiance angle with NDAI and CORR because not only is it most weakly correlated with CORR, but it also gives the highest mutual information when in combination with NDAI and CORR.

Therefore, we have chosen the 3 best features to be NDAI, CORR, and the BF radiance angle because they are all fairly strongly correlated with the response label, they are only moderately correlated with each other, and they all have a relatively high mutual information with the response label.

```{r mutual-information}
library(infotheo)
mutual_info <- function(feature) {
  mutinformation(data$Label, discretize(feature))
}

mi_table <- apply(data[, 5:ncol(data)], MARGIN=2, FUN=mutual_info)
mi_table %>%
  kable(digits=3, col.names=c("Entropy"),
        caption="Mutual Information with Label") %>%
  kable_styling(latex_options="HOLD_position", full_width=F)
```

```{r mutual-information-2}
mi_bf <- mutinformation(data$Label, discretize(data[, c("NDAI", "CORR", "BF")]))
mi_af <- mutinformation(data$Label, discretize(data[, c("NDAI", "CORR", "AF")]))
mi_an <- mutinformation(data$Label, discretize(data[, c("NDAI", "CORR", "BF")]))

mi_table2 <- data.frame(c(mi_bf, mi_af, mi_an))
names(mi_table2) <- "Entropy"
rownames(mi_table2) <- c("NDAI, CORR, BF", "NDAI, CORR, AF", "NDAI, CORR, AN")
mi_table2 %>%
  kable(digits=3, col.names=c("Entropy"),
        caption="Mutual Information with Label") %>%
  kable_styling(latex_options="HOLD_position", full_width=F)
```

## Generic Cross-Validation

We then wrote a function that allows us to pass in the name of a trivial classifier (or a function call to such a classifier), and a number of folds, and outputs the $k$-fold Cross-validation misclassification rate on the training data provided using the classifier. The function uses the block splitting method described in Section 2(a), with $k^2$ blocks per image. It then partitions the blocks into $k$ groups, and, for each partitions, treats that partition as a test set while training the classifier on the other $k-1$ partitions. Finally, the function returns the mean of the misclassification rates of the classifiers predicting on each of the $k$ test partitions. The function also allows for optional arguments, which are then passed to the generic classifier, so as to allow for classifiers to be modified from their generic versions.

```{r}
tl = data %>%
  pull(Label)
td = data %>%
  select(-Label)
CVmaster(td, tl, "rpart", method = "class")
```

# Modeling

# Diagnostics

# References
